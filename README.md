# YOLOV5 V6.0çŸ¥è¯†è’¸é¦

ä¸€äº›ç¢ç¢å¿µï¼š 3050Tiçš„ç®—åŠ›å¤ªå·®äº†ï¼Œyolov5sçš„ batchæœ€å¤§è®¾ä¸º8ï¼Œæ— è¯­å­

--------------
### è°ƒæ•´ä¸€: å…³é—­äº† **wandb** 
 1. `utils/loggers/wandb/wandb_utils.py`
```python
try:
    import wandb

    assert hasattr(wandb, '__version__')  # verify package import not local dir
except (ImportError, AssertionError):
    wandb = None

# ä¿®æ”¹ä¸º
wandb = None
```
 2. `utils/loggers/__init__.py`
```python
try:
    import wandb

    assert hasattr(wandb, '__version__')  # verify package import not local dir
    if pkg.parse_version(wandb.__version__) >= pkg.parse_version('0.12.2') and RANK in [0, -1]:
        try:
            wandb_login_success = wandb.login(timeout=30)
        except wandb.errors.UsageError:  # known non-TTY terminal issue
            wandb_login_success = False
        if not wandb_login_success:
            wandb = None
except (ImportError, AssertionError):
    wandb = None

# ä¿®æ”¹ä¸º
wandb = None
```
### è°ƒæ•´äºŒ: åœ¨train.pyçš„åŸºç¡€ä¸Šå¢åŠ äº†kdæ¡†æ¶ï¼Œåä¸ºï¼štrain_kd.py
 1. å¢åŠ é»˜è®¤å‚æ•°çš„è®¾å®š
```python
# æ˜¯å¦ä½¿ç”¨çŸ¥è¯†è’¸é¦
parser.add_argument('--kd', action='store_true', default=True, help='cache images for faster training')
# é¢„è®­ç»ƒå¥½çš„æ•™å¸ˆç½‘ç»œæ¨¡å‹æƒé‡æ–‡ä»¶åœ°å€
parser.add_argument('--teacher_weight', type=str, default=ROOT / 'runs/weights/YOLOV5M-NO/weights/best.pt',
                        help='initial teacher_weight path')
# ä½¿ç”¨ä½•ç§æŸå¤±å‡½æ•°è®¡ç®—è’¸é¦æŸå¤±
parser.add_argument('--kd_loss_selected', type=str, default='l2', help='using kl/l2 loss in distillation')
# å¦‚æœä½¿ç”¨çš„klè®¡ç®—æŸå¤±ï¼Œåˆ™éœ€è¦æŒ‡å®šæ¸©åº¦temperature
parser.add_argument('--temperature', type=int, default=20, help='temperature in distilling training')
```
 2. åœ¨è®­ç»ƒæµç¨‹ä¸­æ·»åŠ kd
```python
    # åŠ è½½æ•™å¸ˆæ¨¡å‹
    if opt.kd:
        print("load teacher-model from", opt.teacher_weight)
        # load teacher_model
        teacher_model = torch.load(opt.teacher_weight)
        if teacher_model.get("model", None) is not None:
            teacher_model = teacher_model["model"]
        teacher_model.to(device)
        teacher_model.float()
        teacher_model.train()
```
```python   
    # ç”¨äºä¿å­˜ kdæŸå¤±å€¼ 
    mkdloss = torch.zeros(1, device=device)  # mean kd_losses
```
```python
    # å‰å‘ä¼ æ’­ï¼Œä¸æ›´æ–°æ•™å¸ˆç½‘ç»œçš„å‚æ•°
    if opt.kd:
        with torch.no_grad():
            teacher_pred = teacher_model(imgs)
```
```python
    # å°†kdæŸå¤±åŠ å…¥åˆ°æ€»æŸå¤±ï¼Œä»¥ä¾¿åå‘ä¼ æ’­ï¼Œæ›´æ–°å­¦ç”Ÿç½‘ç»œå‚æ•°
    if opt.kd:
        kdloss = compute_kd_output_loss(
            pred, teacher_pred, model, opt.kd_loss_selected, opt.temperature)
    else:
        kdloss = 0
    loss += kdloss
    loss_items[-1] = loss
```
```python
    # æ›´æ–° mkdloss æ—¥å¿—
    mkdloss = (mkdloss * i + kdloss) / (i + 1)  # update mean losses
    pbar.set_description(('%10s' * 2 + '%10.4g' * 6) %
                                     (f'{epoch}/{epochs - 1}', mem, *mloss, mkdloss, targets.shape[0], imgs.shape[-1]))

```
### è°ƒæ•´äºŒ: åœ¨å¤§æ¨¡å‹çš„åŸºç¡€ä¸Šä¿®æ”¹ç½‘ç»œç»“æ„ï¼ˆå¦‚Yolov5m-CAï¼‰ 
 1. æ·»åŠ æ³¨æ„åŠ›æ¨¡å—ï¼ˆæ·»åŠ åˆ° models/common.py ä¸­ï¼‰
```python
# SEæ¨¡å—
class SE(nn.Module):
    def __init__(self, c1, r=16):
        super(SE, self).__init__()
        self.avgpool = nn.AdaptiveAvgPool2d(1)
        self.l1 = nn.Linear(c1, c1 // r, bias=False)
        self.relu = nn.ReLU(inplace=True)
        self.l2 = nn.Linear(c1 // r, c1, bias=False)
        self.sig = nn.Sigmoid()

    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avgpool(x).view(b, c)
        y = self.l1(y)
        y = self.relu(y)
        y = self.l2(y)
        y = self.sig(y)
        y = y.view(b, c, 1, 1)
        return x * y.expand_as(x)
```
```python
# CBAMæ¨¡å—

```
```python
# CAæ¨¡å—

```
 2. ä¿®æ”¹ç½‘ç»œç»“æ„ï¼ˆmodels/yolo.pyï¼‰
```python
# åœ¨ parse_model() å‡½æ•°ä¸‹ç…§ç€æ·»åŠ 
    elif m is SE:
        channel, re = args[0], args[1]
        channel = make_divisible(channel * gw, 8) if channel != no else channel
        args = [channel, re]
```
 3. ä¿®æ”¹é…ç½®æ–‡ä»¶--åœ¨æ¯ä¸ªC3æ¨¡å—åé¢æ·»åŠ ATMï¼ˆå¦‚ä¿®æ”¹ models/yolov5m.yamlï¼‰
```yaml
# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license

# Parameters
nc: 20  # number of classes
depth_multiple: 0.67  # model depth multiple
width_multiple: 0.75  # layer channel multiple
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 v6.0 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, C3, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 6, C3, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, C3, [512]],
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
   [-1, 3, C3, [1024]],
   [-1, 1, SPPF, [1024, 5]],  # 9
  ]

# YOLOv5 v6.0 head
head:
  [[-1, 1, Conv, [512, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 3, C3, [512, False]],  # 13

   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)

   [-1, 1, Conv, [512, 3, 2]],
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)

   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]

```



