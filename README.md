# YOLOV5 V6.0çŸ¥è¯†è’¸é¦

ä¸€äº›ç¢ç¢å¿µï¼š 
- 3050Tiçš„ç®—åŠ›å¤ªå·®äº†ï¼Œyolov5sçš„ batchæœ€å¤§è®¾ä¸º8ï¼Œyolov5mçš„ batchæœ€å¤§è®¾ä¸º4ã€‚æ— è¯­å­..
- å­¦ä¼šäº†AutoDLäº‘æœåŠ¡å™¨çš„ä½¿ç”¨ï¼Œ3090 1.99å…ƒ/h çˆ½


## å¦‚ä½•è®­ç»ƒ
- ä¸‹è½½æ•°æ®é›†ï¼Œç»“æ„å¦‚å›¾æ‰€ç¤ºï¼š

  é“¾æ¥: https://pan.baidu.com/s/1HZIdOi0JOpgVAq-ZI_g5jQ æå–ç : r98i
```shell
.
â”œâ”€â”€ datasets
â”‚Â Â  â””â”€â”€ VOC
â”‚Â Â      â”œâ”€â”€ images
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ test2007
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ train2007
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ train2012
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ val2007
â”‚Â Â      â”‚Â Â  â””â”€â”€ val2012
â”‚Â Â      â””â”€â”€ labels
â”‚Â Â          â”œâ”€â”€ test2007
â”‚Â Â          â”œâ”€â”€ train2007
â”‚Â Â          â””â”€â”€ train2012
```

- è‡ªå·±é¢„è®­ç»ƒå¥½æ•™å¸ˆç½‘ç»œ(ps: å¦‚æœé‡‡ç”¨çš„æ˜¯cocoæ•°æ®é›†åˆ™å¯ä»¥ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼Œå¦åˆ™éœ€è¦è‡ªå·±è®­ç»ƒ)ï¼š
  
  ä¸»è¦æ˜¯å› ä¸ºæ•°æ®é›†çš„ç±»åˆ«æ•°é‡ä¸ä¸€è‡´
  - [yolov5m.pt](https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5m.pt)
  - [yolov5l.pt](https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5l.pt)
  
  ```shell
  cd yolov5-kd
  python train.py --cfg models/yolov5m.yaml --epochs 100 --batch-size 32 --name m --device 0
  python train.py --cfg models/yolov5l.yaml --epochs 100 --batch-size 32 --name l --device 0
  ```
- ```shell
  .
  â”œâ”€â”€ weights
  â”‚Â Â  â””â”€â”€ yolov5m.pt
  â”‚Â Â  â””â”€â”€ yolov5l.pt
  ```

- è’¸é¦è®­ç»ƒ
```shell
  cd yolov5-kd
  # å¦‚æœæ•™å¸ˆç½‘ç»œé‡‡ç”¨mçš„è¯  isL è®¾ä¸º Falseï¼Œ å¦‚æœä¸ºL åˆ™è®¾ä¸º Trueï¼›æš‚æ—¶åªæ”¯æŒ L å¯¹ s æˆ–è€… m å¯¹ sçš„è’¸é¦è®­ç»ƒ
  # YOUR_TEACHER_PT_ROOT æ”¹ä¸ºè‡ªå·±é¢„è®­ç»ƒå¥½çš„æ•™å¸ˆç½‘ç»œptè·¯å¾„
  python train_kd.py --teacher_weight YOUR_TEACHER_PT_ROOT --isL False --epochs 100 --batch-size 32 --name m2s --device 0
  ```


### å¯èƒ½æŠ¥é”™
- æŠ¥é”™1
> 'Upsample' object has no attribute 'recompute_scale_factor'

- åŸå› ï¼štorchç‰ˆæœ¬å¤ªé«˜å¯¼è‡´ç›¸å…³å‡½æ•°å‚æ•°æ”¹å˜
- è§£å†³æ–¹æ³•
```shell
æ‰“å¼€ ç¯å¢ƒroot/lib/python3.x/site-packages/torch/nn/modules/upsampling.py

ä¿®æ”¹ä»£ç 

def forward(self, input: Tensor) -> Tensor:
    return F.interpolate(input, self.size, self.scale_factor, self.mode, self.align_corners)

# return F.interpolate(input, self.size, self.scale_factor, self.mode, self.align_corners,
#                      recompute_scale_factor=self.recompute_scale_factor)
```




## æ›´æ–°æ—¥å¿—
- 2022/5/6  æ–°å¢äº†ç»˜åˆ¶æ›²çº¿å›¾çš„pyæ–‡ä»¶
- 2022/5/5  å¤ç°äº†CDç®—æ³•ï¼Œå®ç°äº†è‡ªå·±çš„åˆ›æ–°ç‚¹
- 2022/4/27 ä¿®æ”¹äº†Conv1_1çš„æ¥å—å‚æ•°å½¢å¼ï¼Œä¸ºäº†åŒ¹é…æ•™å¸ˆç½‘ç»œå’Œå­¦ç”Ÿç½‘ç»œçš„é€šé“æ•°ï¼Œåœ¨å­¦ç”Ÿç½‘ç»œï¼ˆsï¼‰ä¸­æ·»åŠ äº†å¤šä¸ª1 x 1 å·ç§¯
- 2022/4/26 æ›´æ–°äº†æ³¨æ„åŠ›æ¨¡å—ï¼Œä½¿å¾—å…¶èƒ½é€šè¿‡ä¼ å‚çš„å½¢å¼ï¼Œè‡ªé€‚åº”åœ°ç”Ÿæˆï¼šæ­£å¸¸çš„æ³¨æ„åŠ›æ¨¡å—/å…ˆé™ç»´å†æ³¨æ„åŠ›/å…ˆæ³¨æ„åŠ›å†é™ç»´ çš„åŠŸèƒ½
- 2022/4/25 æ”¹è¿›äº†æ•™å¸ˆç½‘ç»œæ¨¡å‹ï¼Œåœ¨å»å¹´V5.0ç‰ˆæœ¬ä¸Šæ–°å¢äº†1 * 1å·ç§¯
- 2022/4/24 åœ¨yolov5 v6.0ç‰ˆæœ¬ä¸Šæ­å»ºå¥½äº† çŸ¥è¯†è’¸é¦æ¡†æ¶

## å…³äºå‚æ•°é‡
### é¢„è®­ç»ƒçš„æ•™å¸ˆç½‘ç»œ
|     Model Name        | layers | parameters |  gradients |  GFLOPs  |
|     -----------       | ------ | ---------- | ---------- | -------- |
|       YOLOv5m         |   369  |  20948097  |  20948097  |   48.3   |


### å­¦ç”Ÿç½‘ç»œ
|     Model Name        | layers | parameters |  gradients |  GFLOPs  |
|     -----------       | ------ | ---------- | ---------- | -------- |
|       YOLOv5s         |   270  |   7073569  |   7073569  |   16.0   |


--------------
## è°ƒæ•´ä¸€: å…³é—­äº† **wandb** 
### 1. `utils/loggers/wandb/wandb_utils.py`
```python
try:
    import wandb

    assert hasattr(wandb, '__version__')  # verify package import not local dir
except (ImportError, AssertionError):
    wandb = None

# ä¿®æ”¹ä¸º
wandb = None
```
### 2. `utils/loggers/__init__.py`
```python
try:
    import wandb

    assert hasattr(wandb, '__version__')  # verify package import not local dir
    if pkg.parse_version(wandb.__version__) >= pkg.parse_version('0.12.2') and RANK in [0, -1]:
        try:
            wandb_login_success = wandb.login(timeout=30)
        except wandb.errors.UsageError:  # known non-TTY terminal issue
            wandb_login_success = False
        if not wandb_login_success:
            wandb = None
except (ImportError, AssertionError):
    wandb = None

# ä¿®æ”¹ä¸º
wandb = None
```
## è°ƒæ•´äºŒ: åœ¨train.pyçš„åŸºç¡€ä¸Šå¢åŠ äº†kdæ¡†æ¶ï¼Œåä¸ºï¼štrain_kd.py
### 1. å¢åŠ é»˜è®¤å‚æ•°çš„è®¾å®š
```python
# æ˜¯å¦ä½¿ç”¨çŸ¥è¯†è’¸é¦
parser.add_argument('--kd', action='store_true', default=True, help='cache images for faster training')
# é¢„è®­ç»ƒå¥½çš„æ•™å¸ˆç½‘ç»œæ¨¡å‹æƒé‡æ–‡ä»¶åœ°å€
parser.add_argument('--teacher_weight', type=str, default=ROOT / 'runs/weights/YOLOV5M-NO/weights/best.pt',
                        help='initial teacher_weight path')
# ä½¿ç”¨ä½•ç§æŸå¤±å‡½æ•°è®¡ç®—è’¸é¦æŸå¤±
parser.add_argument('--kd_loss_selected', type=str, default='l2', help='using kl/l2 loss in distillation')
# å¦‚æœä½¿ç”¨çš„klè®¡ç®—æŸå¤±ï¼Œåˆ™éœ€è¦æŒ‡å®šæ¸©åº¦temperature
parser.add_argument('--temperature', type=int, default=20, help='temperature in distilling training')
```
### 2. åœ¨è®­ç»ƒæµç¨‹ä¸­æ·»åŠ kd
```python
# åœ¨ä½¿ç”¨çš„hyp.yamlæ–‡ä»¶ä¸­æ·»åŠ  è®¡ç®—kdæŸå¤±çš„æ—¶å€™ä¼šç”¨åˆ°çš„å‚æ•°
giou: 0.05
kd: 1.0
```
```python
    # åŠ è½½æ•™å¸ˆæ¨¡å‹
    if opt.kd:
        print("load teacher-model from", opt.teacher_weight)
        teacher_model = torch.load(opt.teacher_weight)
        if teacher_model.get("model", None) is not None:
            teacher_model = teacher_model["model"]
        teacher_model.to(device)
        teacher_model.float()
        teacher_model.train()
```
```python
    # ç”¨äºä¿å­˜ kdæŸå¤±å€¼ 
    mkdloss = torch.zeros(1, device=device)  # mean kd_losses
    matloss = torch.zeros(1, device=device)  # mean at_losses
```
```python
    # å‰å‘ä¼ æ’­ï¼Œä¸æ›´æ–°æ•™å¸ˆç½‘ç»œçš„å‚æ•°
    if opt.kd:
        with torch.no_grad():
            teacher_pred = teacher_model(imgs)
```
```python
    # å°†kdæŸå¤±åŠ å…¥åˆ°æ€»æŸå¤±ï¼Œä»¥ä¾¿åå‘ä¼ æ’­ï¼Œæ›´æ–°å­¦ç”Ÿç½‘ç»œå‚æ•°
    # Forward
    with amp.autocast(enabled=cuda):
        s_f = get_feas_by_hook(model) # è·å–å­¦ç”Ÿç½‘ç»œä¸­é—´å±‚ç‰¹å¾
        pred = model(imgs)  # forward

        if opt.kd:
            atloss = torch.zeros(1, device=device)
            with torch.no_grad():
                t_f = get_t_feas_by_hook(teacher_model) # è·å–æ•™å¸ˆç½‘ç»œä¸­é—´å±‚ç‰¹å¾
                teacher_pred = teacher_model(imgs)

            for i in range(len(t_f)):
                # è®¡ç®—ATloss
                atloss += at_loss(s_f[i].fea, t_f[i].fea)
        
        del s_f, t_f

        loss, loss_items = compute_loss(pred, targets.to(device))  # loss scaled by batch_size
        # kd
        if opt.kd:
            kdloss = compute_kd_output_loss(
                pred, teacher_pred, model, opt.kd_loss_selected, opt.temperature)
        else:
            kdloss = 0
        del teacher_pred
        loss += opt.alpha * kdloss + opt.beta * atloss
        kdloss_items = kdloss.detach()
        atloss_items = atloss.detach()

        if RANK != -1:
            loss *= WORLD_SIZE  # gradient averaged between devices in DDP mode
        if opt.quad:
            loss *= 4.
```
```python
    # æ›´æ–° mkdloss æ—¥å¿—
    mkdloss = (mkdloss * i + kdloss_items) / (i + 1)  # update mean losses
    matloss = (matloss * i + atloss_items) / (i + 1)  # update mean losses
    pbar.set_description(('%10s' * 2 + '%10.4g' * 7) %
                         (f'{epoch}/{epochs - 1}', mem, *mloss, mkdloss, matloss, targets.shape[0], imgs.shape[-1]))

```

### 3. æ–°å¢æŸå¤±å‡½æ•°çš„è®¡ç®—
```python
def compute_kd_output_loss(pred, teacher_pred, model, kd_loss_selected="l2", temperature=20, reg_norm=None):
    t_ft = torch.cuda.FloatTensor if teacher_pred[0].is_cuda else torch.Tensor
    t_lcls, t_lbox, t_lobj = t_ft([0]), t_ft([0]), t_ft([0])
    h = model.hyp  # hyperparameters
    red = 'mean'  # Loss reduction (sum or mean)
    if red != "mean":
        raise NotImplementedError(
            "reduction must be mean in distillation mode!")

    KDboxLoss = nn.MSELoss(reduction="none")
    if kd_loss_selected == "l2":
        KDclsLoss = nn.MSELoss(reduction="none")
    elif kd_loss_selected == "kl":
        KDclsLoss = nn.KLDivLoss(reduction="none")
    else:
        KDclsLoss = nn.BCEWithLogitsLoss(reduction="none")
    KDobjLoss = nn.MSELoss(reduction="none")
    # per output
    for i, pi in enumerate(pred):  # layer index, layer predictions
        # t_pi  -->  torch.Size([16, 3, 80, 80, 25])
        t_pi = teacher_pred[i]
        # t_obj_scale  --> torch.Size([16, 3, 80, 80])
        t_obj_scale = t_pi[..., 4].sigmoid()
        # zero = torch.zeros_like(t_obj_scale)
        # t_obj_scale = torch.where(t_obj_scale < 0.5, zero, t_obj_scale)

        # BBox
        # repeat æ˜¯æ²¿ç€åŸæ¥çš„ç»´åº¦åšå¤åˆ¶  torch.Size([16, 3, 80, 80, 4])
        b_obj_scale = t_obj_scale.unsqueeze(-1).repeat(1, 1, 1, 1, 4)
        if not reg_norm:
            t_lbox += torch.mean(KDboxLoss(pi[..., :4], t_pi[..., :4]) * b_obj_scale)
        else:
            wh_norm_scale = reg_norm[i].unsqueeze(0).unsqueeze(-2).unsqueeze(-2)
            # pxy
            t_lbox += torch.mean(KDboxLoss(pi[..., :2].sigmoid(), t_pi[..., :2].sigmoid()) * b_obj_scale)
            # pwh
            t_lbox += torch.mean(
                KDboxLoss(pi[..., 2:4].sigmoid(), t_pi[..., 2:4].sigmoid() * wh_norm_scale) * b_obj_scale)

        # Class
        if model.nc > 1:  # cls loss (only if multiple classes)
            c_obj_scale = t_obj_scale.unsqueeze(-1).repeat(1, 1, 1, 1, model.nc)
            if kd_loss_selected == "kl":
                kl_loss = KDclsLoss(F.log_softmax(pi[..., 5:] / temperature, dim=-1),
                                    F.softmax(t_pi[..., 5:] / temperature, dim=-1)) * (temperature * temperature)
                t_lcls += torch.mean(kl_loss * c_obj_scale)
            else:
                t_lcls += torch.mean(KDclsLoss(pi[..., 5:], t_pi[..., 5:]) * c_obj_scale)

        t_lobj += torch.mean(KDobjLoss(pi[..., 4], t_pi[..., 4]) * t_obj_scale)
    t_lbox *= h['giou'] * h['kd']
    t_lobj *= h['obj'] * h['kd']
    t_lcls *= h['cls'] * h['kd']
    bs = pred[0].shape[0]  # batch size
    mkdloss = (t_lobj + t_lbox + t_lcls) * bs
    return mkdloss



def ft(x):
    return F.normalize(x.pow(2).mean(2).mean(2).view(x.size(0), -1))


def at(x):
    return F.normalize(x.pow(2).mean(1).view(x.size(0), -1))


def at_loss(x, y):
    return (at(x) - at(y)).pow(2).mean()
```
### 4. ä¿®æ”¹äº†æ¨¡å‹çš„ä¿å­˜æ–¹å¼
```python
# åŸ
'model': deepcopy(de_parallel(model)).half(),
# ç°
'model': model.state_dict(),
```

------------

## è°ƒæ•´äºŒ: åœ¨å¤§æ¨¡å‹çš„åŸºç¡€ä¸Šä¿®æ”¹ç½‘ç»œç»“æ„ï¼ˆå¦‚Yolov5m-CAï¼‰ 
### 1. æ·»åŠ æ³¨æ„åŠ›æ¨¡å—ï¼ˆæ·»åŠ åˆ° models/common.py ä¸­ï¼‰
```python
# SEæ¨¡å—
class SELayer(nn.Module):
    def __init__(self, inp, oup, r=16, need11=False, reverse=False):
        super(SELayer, self).__init__()
        self.need11 = need11
        self.reverse = reverse
        true_oup = inp
        if self.need11 and not self.reverse:
            true_oup = oup
        self.conv_match = nn.Conv2d(inp, oup, kernel_size=1, stride=1, padding=0)
        self.avgpool = nn.AdaptiveAvgPool2d(1)
        self.l1 = nn.Linear(true_oup, true_oup // r, bias=False)
        self.relu = nn.ReLU(inplace=True)
        self.l2 = nn.Linear(true_oup // r, true_oup, bias=False)
        self.sig = nn.Sigmoid()

    def forward(self, x):
        if self.need11 and not self.reverse:
            x = self.conv_match(x)
        b, c, _, _ = x.size()
        y = self.avgpool(x).view(b, c)
        y = self.l1(y)
        y = self.relu(y)
        y = self.l2(y)
        y = self.sig(y)
        y = y.view(b, c, 1, 1)
        out = x * y.expand_as(x)
        if self.need11 and self.reverse:
            out = self.conv_match(out)
        return out
```
```python
# CBAMæ¨¡å—
class ASCBAM(nn.Module):
    # Standard convolution
    def __init__(self, inp, oup, ratio=4, need11=False, reverse=False):  # ch_in, ch_out, kernel, stride, padding, groups
        super(ASCBAM, self).__init__()
        self.need11 = need11
        self.reverse = reverse
        true_oup = inp
        if self.need11 and not self.reverse:
            true_oup = oup
        self.conv_match = nn.Conv2d(inp, oup, kernel_size=1, stride=1, padding=0)
        self.ca = ChannelAttention(true_oup, ratio, AS=False)
        self.sa = SpatialAttention(true_oup, AS=False)

    def forward(self, x):
        if self.need11 and not self.reverse:
            x = self.conv_match(x)
        out = self.sa(self.ca(x))
        if self.need11 and self.reverse:
            out = self.conv_match(out)
        return out


# add CBAM
class SpatialAttention(nn.Module):
    def __init__(self, in_planes, kernel_size=7, AS=False):
        super(SpatialAttention, self).__init__()
        self.conv3 = nn.Conv2d(in_planes, in_planes, 3, padding=1)
        self.conv1_1 = nn.Conv2d(in_planes, in_planes, 1)
        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=3, bias=False)  # concatå®Œchannelç»´åº¦ä¸º2
        self.sigmoid = nn.Sigmoid()
        self.AS = AS

    def forward(self, x):
        if self.AS:
            avg_out = torch.mean(x, dim=1, keepdim=True)
            max_out = self.sigmoid(self.conv1_1(self.conv3(x)))
            max_out1, _ = torch.max(max_out, dim=1, keepdim=True)
            y = torch.cat([avg_out, max_out1], dim=1)  # æ²¿ç€channelç»´åº¦concatä¸€å—
        else:
            avg_out = torch.mean(x, dim=1, keepdim=True)  # æ²¿ç€channel ç»´åº¦è®¡ç®—å‡å€¼å’Œæœ€å¤§å€¼
            max_out1, _ = torch.max(x, dim=1, keepdim=True)
            y = torch.cat([avg_out, max_out1], dim=1)  # æ²¿ç€channelç»´åº¦concatä¸€å—
        y = self.conv1(y)
        y = self.sigmoid(y)
        return x * y


class ChannelAttention(nn.Module):
    def __init__(self, in_planes, ratio=16, AS=False):
        super(ChannelAttention, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
        self.max_pool_3d = nn.AdaptiveAvgPool3d((in_planes, 1, 1))

        self.conv3 = nn.Conv2d(in_planes, in_planes * 2, 3)
        self.fc1 = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)
        self.relu1 = nn.ReLU()
        self.fc2 = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)
        self.sigmoid = nn.Sigmoid()
        self.AS = AS

    def forward(self, x):
        if self.AS:
            max_out = self.fc2(self.relu1(self.fc1(self.max_pool_3d(self.conv3(x)))))
            avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))
        else:
            avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))
            max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))
        out = avg_out + max_out
        return x * self.sigmoid(out)
```
```python
# CAæ¨¡å—
class CABlock(nn.Module):
    def __init__(self, inp, oup, reduction=32, need11=False, reverse=False):
        super(CABlock, self).__init__()
        self.need11 = need11
        self.reverse = reverse
        true_oup = inp
        if self.need11 and not self.reverse:
            true_oup = oup
        self.conv_match = nn.Conv2d(inp, oup, kernel_size=1, stride=1, padding=0)
        self.pool_h = nn.AdaptiveAvgPool2d((None, 1))
        self.pool_w = nn.AdaptiveAvgPool2d((1, None))
        mip = max(8, true_oup // reduction)
        self.conv1 = nn.Conv2d(true_oup, mip, kernel_size=1, stride=1, padding=0)
        self.bn1 = nn.BatchNorm2d(mip)
        self.act = h_swish()
        self.conv_h = nn.Conv2d(mip, true_oup, kernel_size=1, stride=1, padding=0)
        self.conv_w = nn.Conv2d(mip, true_oup, kernel_size=1, stride=1, padding=0)

    def forward(self, x):
        if self.need11 and not self.reverse:
            x = self.conv_match(x)
        identity = x
        n, c, h, w = x.size()
        x_h = self.pool_h(x)
        x_w = self.pool_w(x).permute(0, 1, 3, 2)
        y = torch.cat([x_h, x_w], dim=2)
        y = self.conv1(y)
        y = self.bn1(y)
        y = self.act(y)
        x_h, x_w = torch.split(y, [h, w], dim=2)
        x_w = x_w.permute(0, 1, 3, 2)
        a_h = self.conv_h(x_h).sigmoid()
        a_w = self.conv_w(x_w).sigmoid()
        out = identity * a_w * a_h
        if self.need11 and self.reverse:
            out = self.conv_match(out)
        return out
```
### 2. ä¿®æ”¹ç½‘ç»œç»“æ„ï¼ˆmodels/yolo.pyï¼‰
```python
# åœ¨ parse_model() å‡½æ•°ä¸‹ç…§ç€æ·»åŠ 
    elif m is Conv1_1:
        args = [args[0], args[1]]
    elif m is SELayer:
        channel = args[0]
        channel = make_divisible(channel * gw, 8) if channel != no else channel
        args = [channel, args[0] // 2, *args[1:]]
    elif m is CABlock:
        channel = args[0]
        channel = make_divisible(channel * gw, 8) if channel != no else channel
        args = [channel, args[0] // 2, *args[1:]]
    elif m is ASCBAM:
        channel = args[0]
        channel = make_divisible(channel * gw, 8) if channel != no else channel
        args = [channel, args[0] // 2, *args[1:]]
```
### 3. ä¿®æ”¹é…ç½®æ–‡ä»¶--åœ¨æ¯ä¸ªC3æ¨¡å—åé¢æ·»åŠ ATMï¼ˆå¦‚ä¿®æ”¹ models/yolov5m.yamlï¼‰
```yaml
# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license

# Parameters
nc: 20  # number of classes
depth_multiple: 0.67  # model depth multiple
width_multiple: 0.75  # layer channel multiple
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 v6.0 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, C3, [128]],    # 2
   [-1, 1, SELayer, [128, 4]], # 3
   [-1, 1, Conv, [256, 3, 2]],  # 4-P3/8
   [-1, 6, C3, [256]],
   [-1, 1, SELayer, [256, 4]], #6
   [-1, 1, Conv, [512, 3, 2]],  # 7-P4/16
   [-1, 9, C3, [512]],
   [-1, 1, SELayer, [512, 4]], # 9
   [-1, 1, Conv, [1024, 3, 2]],  # 10 -P5/32
   [-1, 3, C3, [1024]],
   [-1, 1, SELayer, [1024, 4]], #12
   [-1, 1, SPPF, [1024, 5]],  # 13
  ]

# YOLOv5 head
head:
  [[-1, 1, Conv, [512, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 9], 1, Concat, [1]],  # cat backbone P4
   [-1, 3, C3, [512, False]],  # 17
   [ -1, 1, SELayer, [512, 4] ], #18

   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P3
   [-1, 3, C3, [256, False]],  # 22 (P3/8-small)
   [ -1, 1, SELayer, [256, 4] ], #23

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 19], 1, Concat, [1]],  # cat head P4
   [-1, 3, C3, [512, False]],  # 26 (P4/16-medium)
   [ -1, 1, SELayer, [512, 4] ], #27

   [-1, 1, Conv, [512, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P5
   [-1, 3, C3, [1024, False]],  # 30 (P5/32-large)
   [ -1, 1, SELayer, [1024, 4] ], #31

   [[23, 27, 31], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]
```

## è°ƒæ•´ä¸‰ï¼šå°†ä¸­é—´å±‚ç‰¹å¾å›¾åŒ¹é…ä¸Š
```python
# æ•™å¸ˆç½‘ç»œï¼ˆYolov5mï¼‰ä¸­é—´å±‚ç‰¹å¾shape        # å­¦ç”Ÿç½‘ç»œï¼ˆYolov5sï¼‰ä¸­é—´å±‚ç‰¹å¾shape    # diffChannel
    torch.Size([8, 96, 160, 160])               <-->     torch.Size([8, 64, 160, 160])         32   
    torch.Size([8, 192, 80, 80])                <-->     torch.Size([8, 128, 80, 80])          64
    torch.Size([8, 384, 40, 40])                <-->     torch.Size([8, 256, 40, 40])          128
    torch.Size([8, 768, 20, 20])                <-->     torch.Size([8, 512, 20, 20])          256
    torch.Size([8, 384, 40, 40])                <-->     torch.Size([8, 256, 40, 40])          128
    torch.Size([8, 192, 80, 80])                <-->     torch.Size([8, 128, 80, 80])          64
    torch.Size([8, 384, 40, 40])                <-->     torch.Size([8, 256, 40, 40])          32
    torch.Size([8, 768, 20, 20])                <-->     torch.Size([8, 512, 20, 20])          256
# Yolov5l:
    torch.Size([2, 128, 160, 160])
    torch.Size([2, 256, 80, 80])
    torch.Size([2, 512, 40, 40])
    torch.Size([2, 1024, 20, 20])
    torch.Size([2, 512, 40, 40])
    torch.Size([2, 256, 80, 80])
    torch.Size([2, 512, 40, 40])
    torch.Size([2, 1024, 20, 20])
```





